{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to RadBurst Documentation","text":"<p>This documentation provides a guide to the software developed for the MDP Heliophysics Research Team. The goal is to detect and classify solar radio bursts from spectrogram data collected by our LWA antennas.</p> <p>Below are links to key sections of the documentation:</p>"},{"location":"#developer-guide","title":"Developer Guide","text":"<ul> <li>Installation: Instructions for setting up the project on your local machine.</li> <li>Development Workflow: Best practices and guidelines for contributing to the project.</li> <li>Updating Documentation: Instructions for maintaining and updating documentation.</li> </ul>"},{"location":"#code-reference","title":"Code Reference","text":"<ul> <li>Reference Overview: Overview of the codebase structure and main components.</li> <li>Utilities: General utility functions for data handling and visualization.</li> <li>Preprocessing: Functions for data preprocessing and standardization.</li> <li>Detection: Algorithms for detecting solar radio bursts.</li> <li>Classification: CNN-based classification of solar radio bursts.</li> </ul>"},{"location":"#examples","title":"Examples","text":"<ul> <li>Examples:</li> </ul>"},{"location":"#repository-structure","title":"Repository Structure","text":"<pre><code>data/                   # Explanations and links to datasets and sample data\ndocs/                   # Documentation (.md files)\nnotebooks/              # Jupyter notebooks\n    exploration/        # Notebooks for data exploration, testing ideas and analysis        \n    evaluation/         # Notebooks evaluating models and algorithms\n    examples/           # Notebooks demonstrating how to use code\nradburst/               # Main directory for code developement\n    detection/          # Burst detection code\n    classification/     # Burst classification code\n    utils/              # Common utility functions (e.g. load, preprocess, etc.)\nrequirements.txt        # Project dependencies (read by setup.py when \"pip install -e .\" is run)\nmkdocs.yml              # Configuration for MkDocs documentation\n</code></pre>"},{"location":"code_reference/","title":"Overview","text":"<p>This section provides a comprehensive reference for the RadBurst codebase. It covers the main components of the project, including utilities, detection algorithms, and classification models.</p>"},{"location":"code_reference/#structure","title":"Structure","text":"<p>The RadBurst project is organized into several key modules:</p> <ol> <li>Utilities: Common functions and tools used throughout the project.</li> <li>Preprocessing: Data preprocessing functions.</li> <li> <p>General Utilities: General-purpose utility functions.</p> </li> <li> <p>Detection: Algorithms and methods for detecting solar radio bursts.</p> </li> <li> <p>Detection Algorithms: Overview of burst detection techniques.</p> </li> <li> <p>Classification: Models and methods for classifying detected bursts.</p> </li> <li>Classification Models: Details on the CNN-based classification system.</li> </ol> <p>Each subsection provides in-depth documentation on the respective module's functions, classes, and usage examples.</p>"},{"location":"code_reference/classification/classification/","title":"CNN Classification of Radio Bursts","text":""},{"location":"code_reference/classification/classification/#overview","title":"Overview","text":"<p>This part of the SunRise Project implements a Convolutional Neural Network (CNN) for classifying solar radio bursts. The model is designed to categorize spectrograms of radio emissions into different types of solar bursts or non-burst events.</p>"},{"location":"code_reference/classification/classification/#dataset","title":"Dataset","text":"<p>The dataset consists of spectrograms of radio emissions from various solar observatories, stored as parquet files. Each spectrogram is associated with metadata, including the type of burst (if any) and the instrument that recorded it.</p>"},{"location":"code_reference/classification/classification/#data-loading-and-preprocessing","title":"Data Loading and Preprocessing","text":"<p>The dataset is loaded using a custom <code>SpectrogramDataset</code> class, which handles:</p> <ol> <li>Reading the metadata from a CSV file</li> <li>Loading spectrogram data from parquet files</li> <li>Applying preprocessing transformations</li> </ol> <p>Key preprocessing steps include:</p> <ul> <li>Cleaning the spectrograms (likely removing noise or artifacts)</li> <li>Converting the data to PyTorch tensors</li> </ul> <p>```38:44:ML_CNN_multi.ipynb    \"outputs\": [     {      \"name\": \"stdout\",      \"output_type\": \"stream\",      \"text\": [       \"Unique values in 'instruments': ['Australia-ASSA_62']\\n\",       \"extracted:       datetime_start datetime_end        instruments type  \\\\n\", <pre><code>## Model Architecture\n\nThe CNN model consists of the following layers:\n\n1. Four convolutional layers, each followed by ReLU activation, batch normalization, and max pooling\n2. A dropout layer for regularization\n3. Two fully connected layers\n\nThe model can be configured for either binary classification (burst vs. no burst) or multi-class classification (different types of bursts).\n\n## Training\n\nThe training process includes:\n\n1. Splitting the data into training and testing sets\n2. Using Adam optimizer with a learning rate scheduler\n3. Employing either Binary Cross Entropy Loss (for binary classification) or Cross Entropy Loss (for multi-class classification)\n4. Training for multiple epochs with batch processing\n\n## Evaluation\n\nThe model's performance is evaluated using:\n\n1. Confusion Matrix: Visualizes the model's predictions against true labels\n2. Accuracy: Overall correctness of predictions\n3. Balanced Accuracy: Accounts for imbalanced datasets by considering both True Positive Rate (TPR) and True Negative Rate (TNR)\n\n```324:331:ML_CNN_multi.ipynb\n      \"Train with multi-class:\\n\",\n      \"torch.Size([32, 4]) torch.Size([32, 4])\\n\",\n      \"output: tensor([[ 0.2891, -1.9227, -0.9357, -1.5601],\\n\",\n      \"        [-0.1225, -2.0723,  1.9852, -0.4430],\\n\",\n      \"        [ 0.0236, -1.4689,  1.0078, -1.6238],\\n\",\n      \"        [-2.7489, -2.2627,  1.2177,  0.2870],\\n\",\n      \"        [-2.1536, -1.9636,  1.4792,  0.2309],\\n\",\n      \"        [-2.7985, -1.3299,  1.2968,  0.1508],\\n\",\n</code></pre></p>"},{"location":"code_reference/classification/classification/#prediction","title":"Prediction","text":"<p>The trained model can be used to classify new spectrograms. The process involves:</p> <ol> <li>Loading and preprocessing a spectrogram</li> <li>Passing it through the model</li> <li>Interpreting the output (either as a binary classification or multi-class probabilities)</li> </ol>"},{"location":"code_reference/classification/classification/#future-improvements","title":"Future Improvements","text":"<ol> <li>Fine-tuning hyperparameters for better performance</li> <li>Implementing more advanced data augmentation techniques</li> <li>Exploring ensemble methods or more complex architectures</li> <li>Use data from Peach Mountain to furhter improve generalization</li> </ol>"},{"location":"code_reference/detection/detection/","title":"Solar Radio Burst Detection","text":""},{"location":"code_reference/detection/detection/#overview","title":"Overview","text":"<p>This module focuses on the detection of solar radio bursts from spectrogram data. The detection process is a crucial first step in identifying and classifying these phenomena.</p>"},{"location":"code_reference/detection/detection/#key-components","title":"Key Components","text":"<ol> <li> <p>Preprocessing: Before detection, the spectrogram data typically undergoes preprocessing steps such as noise reduction and normalization. These steps are crucial for improving the detection accuracy.</p> </li> <li> <p>Detection Algorithm: The core of this module is the burst detection algorithm. While the specific implementation details are not provided in the current codebase, common approaches include:</p> </li> <li>Drift Rate-based detection</li> <li> <p>Machine learning-based anomaly detection</p> </li> <li> <p>Post-processing: After initial detection, post-processing steps may be applied to refine the results, such as merging nearby detections or filtering out false positives.</p> </li> </ol>"},{"location":"code_reference/detection/detection/#usage","title":"Usage","text":"<p>To use the detection module, you typically would:</p> <ol> <li> <p>Load the spectrogram data using the utility functions</p> </li> <li> <p>Preprocess the data:</p> </li> <li> <p>Apply the detection algorithm (placeholder as the actual implementation is not provided):</p> </li> </ol>"},{"location":"code_reference/detection/detection/#future-improvements","title":"Future Improvements","text":"<ul> <li>Implement and document specific detection algorithms</li> <li>Add performance metrics for evaluating detection accuracy</li> <li>Integrate detection results with the classification module</li> </ul>"},{"location":"code_reference/utils/dataset/","title":"Dataset Class","text":"<p>Import Dataset from the <code>dataset</code> module:</p> <pre><code>from radburst.utils.dataset import Dataset\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset","title":"radburst.utils.dataset","text":""},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset","title":"Dataset","text":"<pre><code>Dataset(data_dir, labels, preprocess=None, binary=True)\n</code></pre> <p>Dataset class to manage loading, storing and processing data.</p> <p>Intialize the dataset.</p> PARAMETER DESCRIPTION <code>data_dir</code> <p>The root directory containing the FITS data files.</p> <p> TYPE: <code>str</code> </p> <code>labels</code> <p>Path to csv file containing labels (paths and burst types) or labels dataframe</p> <p> TYPE: <code>str or DataFrame</code> </p> <code>preprocess</code> <p>Function that takes a spectrogram array and returns a preprocessed array.                              Defaults to None.</p> <p> TYPE: <code>callable</code> DEFAULT: <code>None</code> </p> <code>binary</code> <p>True for binary labels: 0 and 1 for no burst and burst                      False for type labels: burst number for burst, 0 for no burst</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> ATTRIBUTE DESCRIPTION <code>data_dir</code> <p>The directory path for the dataset.</p> <p> TYPE: <code>str</code> </p> <code>data</code> <p>List that stores the loaded data arrays from FITS files.</p> <p> TYPE: <code>list</code> </p> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def __init__(self, data_dir, labels, preprocess=None, binary=True):\n    \"\"\"Intialize the dataset.\n\n    Args:\n        data_dir (str): The root directory containing the FITS data files.\n        labels (str or pd.DataFrame): Path to csv file containing labels (paths and burst types) or labels dataframe\n        preprocess (callable, optional): Function that takes a spectrogram array and returns a preprocessed array.\n                                         Defaults to None.\n        binary (bool, optional): True for binary labels: 0 and 1 for no burst and burst\n                                 False for type labels: burst number for burst, 0 for no burst\n\n    Attributes:\n        data_dir (str): The directory path for the dataset.\n        data (list): List that stores the loaded data arrays from FITS files.\n    \"\"\"\n    self.data_dir = data_dir\n    self.binary = binary\n    self.preprocess = preprocess\n\n    # Load labels data\n    if isinstance(labels, str):\n        self.labels_df = pd.read_csv(labels)\n    elif isinstance(labels, pd.DataFrame):\n        self.labels_df = labels\n    else:\n        raise TypeError('labels must be a str path or a pd.DataFrame')\n\n    self.paths = self.labels_df['path']\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.data_dir","title":"data_dir  <code>instance-attribute</code>","text":"<pre><code>data_dir = data_dir\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.binary","title":"binary  <code>instance-attribute</code>","text":"<pre><code>binary = binary\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.preprocess","title":"preprocess  <code>instance-attribute</code>","text":"<pre><code>preprocess = preprocess\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.labels_df","title":"labels_df  <code>instance-attribute</code>","text":"<pre><code>labels_df = read_csv(labels)\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.paths","title":"paths  <code>instance-attribute</code>","text":"<pre><code>paths = labels_df['path']\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx)\n</code></pre> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def __getitem__(self, idx):\n\n    # Load file\n    file_path = os.path.join(self.data_dir, self.labels_df['path'].iloc[idx])\n    spectrogram_arr = utils.load_fits_file(file_path)\n\n    # Get label for file\n    if self.binary:\n        label = self.labels_df['burst'].iloc[idx]\n    else:\n        label = self.labels_df['type'].iloc[idx]\n\n    # Preprocss\n    if self.preprocess:\n        spectrogram_arr = self.preprocess(spectrogram_arr)\n\n    return spectrogram_arr, label\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def __len__(self):\n    return len(self.labels_df)\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.get_filtered_dataset","title":"get_filtered_dataset","text":"<pre><code>get_filtered_dataset(condition)\n</code></pre> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def get_filtered_dataset(self, condition):\n    new_labels = self.labels_df.query(condition).reset_index(drop=True)\n    new_dataset = Dataset(data_dir=self.data_dir,\n                          labels=new_labels,\n                          preprocess=self.preprocess,\n                          binary=self.preprocess)\n    return new_dataset\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.only_bursts","title":"only_bursts","text":"<pre><code>only_bursts()\n</code></pre> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def only_bursts(self):\n    return self.get_filtered_dataset(condition='burst == 1')\n</code></pre>"},{"location":"code_reference/utils/dataset/#radburst.utils.dataset.Dataset.only_nonbursts","title":"only_nonbursts","text":"<pre><code>only_nonbursts()\n</code></pre> Source code in <code>radburst/utils/dataset.py</code> <pre><code>def only_nonbursts(self):\n    return self.get_filtered_dataset(condition='burst == 0')\n</code></pre>"},{"location":"code_reference/utils/preprocessing/","title":"Preprocessing Functions","text":"<p>Import preprocessing functions from the <code>preprocessing</code> module:</p> <pre><code>from radburst.utils.preprocessing import standardize_rows\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing","title":"radburst.utils.preprocessing","text":""},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.BinaryMaskRegion","title":"BinaryMaskRegion","text":"<pre><code>BinaryMaskRegion(bbox)\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def __init__(self, bbox):\n    self.min_row, self.min_col, self.max_row, self.max_col = bbox\n    self.height = self.max_row - self.min_row\n    self.width = self.max_col - self.min_col\n    self.hw_ratio = self.height / self.width\n    self.area = self.height * self.width\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.BinaryMaskRegion.height","title":"height  <code>instance-attribute</code>","text":"<pre><code>height = max_row - min_row\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.BinaryMaskRegion.width","title":"width  <code>instance-attribute</code>","text":"<pre><code>width = max_col - min_col\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.BinaryMaskRegion.hw_ratio","title":"hw_ratio  <code>instance-attribute</code>","text":"<pre><code>hw_ratio = height / width\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.BinaryMaskRegion.area","title":"area  <code>instance-attribute</code>","text":"<pre><code>area = height * width\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.RegionManager","title":"RegionManager","text":"<pre><code>RegionManager()\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def __init__(self):\n    self.regions = []\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.RegionManager.regions","title":"regions  <code>instance-attribute</code>","text":"<pre><code>regions = []\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.RegionManager.add_region","title":"add_region","text":"<pre><code>add_region(region)\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def add_region(self, region):\n    self.regions.append(region)\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.RegionManager.filter_largest_2_regions","title":"filter_largest_2_regions","text":"<pre><code>filter_largest_2_regions(row_diff_threshold=50, size_ratio_threshold=10)\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def filter_largest_2_regions(self, row_diff_threshold=50, size_ratio_threshold=10):\n    if len(self.regions) &lt; 2: return self.regions\n\n    # sometimes mask images have one large low (high row) region and one small high (low row) region \n    # higest row = low frequency\n\n    largest_2_regions = self._get_largest_2_regions()\n    largest_reg = largest_2_regions[1]\n    second_largest_reg = largest_2_regions[0]\n\n    max_row_diff = largest_reg.max_row - second_largest_reg.max_row\n    size_ratio = largest_reg.area / second_largest_reg.area        \n\n    # if difference in highest row is greater than threshold, keep region with greater max row (lower in image)\n    if abs(max_row_diff) &gt; row_diff_threshold:\n        return [largest_reg] if max_row_diff &gt; 0 else [second_largest_reg]\n\n    # if the largest is greater than some factor larger than the second largest, only keep largest\n    if size_ratio &gt; size_ratio_threshold:\n        return [largest_reg]\n\n    return largest_2_regions\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.standardize_rows","title":"standardize_rows","text":"<pre><code>standardize_rows(arr)\n</code></pre> <p>Standardize each row by subtracting the mean and dividing by the standard deviation.</p> PARAMETER DESCRIPTION <code>arr</code> <p>Array to standardize.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <p>np.ndarray: Row-standardized 2D array.</p> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def standardize_rows(arr):\n    \"\"\"Standardize each row by subtracting the mean and dividing by the standard deviation.\n\n    Args:\n        arr (np.ndarray): Array to standardize.\n\n    Returns:\n        np.ndarray: Row-standardized 2D array.\n    \"\"\"\n    mean_per_row = np.mean(arr, axis=1, keepdims=True)\n    std_per_row = np.std(arr, axis=1, keepdims=True)\n\n    # Prevent divide by 0 errors\n    epsilon = 1e-8\n    std_per_row = np.maximum(std_per_row, epsilon)\n\n    standardized_arr = (arr - mean_per_row) / std_per_row\n\n    return standardized_arr\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.remove_vertical_lines","title":"remove_vertical_lines","text":"<pre><code>remove_vertical_lines(arr, num_std=5, dist=10)\n</code></pre> <p>Remove columns with high variance (vertical lines) with other columns some distance away.</p> <p>The default value of 5 seems to be a value based on a few random samples but this could be further verified.  For the dist, we can see that these vertical lines are always just a few columns so 10 is far enough away to  get a replacement column.</p> PARAMETER DESCRIPTION <code>arr</code> <p>Array to process.</p> <p> TYPE: <code>ndarray</code> </p> <code>num_std</code> <p>Number of standard deviations above the mean to use as threshold for vertical lines.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>dist</code> <p>Distance away from vertical line column to get replacement column.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <p>np.ndarray: Processed array with vertical lines removed.</p> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def remove_vertical_lines(arr, num_std = 5, dist = 10):\n    \"\"\"Remove columns with high variance (vertical lines) with other columns some distance away.\n\n    The default value of 5 seems to be a value based on a few random samples but this could be further verified. \n    For the dist, we can see that these vertical lines are always just a few columns so 10 is far enough away to \n    get a replacement column.\n\n    Args:\n        arr (np.ndarray): Array to process.\n        num_std (int): Number of standard deviations above the mean to use as threshold for vertical lines.\n        dist (int): Distance away from vertical line column to get replacement column.\n\n    Returns:\n        np.ndarray: Processed array with vertical lines removed.\"\"\"\n\n    # Calculate variance of each column\n    vars = np.var(arr, axis=0, ddof=0)\n\n    # Calculate the mean and standard deviation of the variances\n    mean_var = np.mean(vars)\n    std_var = np.std(vars)\n\n    # Calculate the threshold for detecting columns that contain unwanted vertical liens\n    var_threshold = mean_var + num_std * std_var\n\n    # Find indices of columns with variance greater than threshold\n    high_var_cols = np.where(vars &gt; var_threshold)[0]\n\n    # Replace high variance columns with other columns some distance away\n        # We know the vertical lines are only a few cols wide\n    arr_verts_removed = arr.copy()\n    for i in high_var_cols:\n        col_to_replace_vert_line = (i - dist) if (i &gt;= dist) else (i + dist)\n        arr_verts_removed[:,i] = arr[:,col_to_replace_vert_line]\n\n    return arr_verts_removed\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.stan_rows_remove_verts","title":"stan_rows_remove_verts","text":"<pre><code>stan_rows_remove_verts(arr)\n</code></pre> <p>Standardize rows and remove vertical lines</p> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def stan_rows_remove_verts(arr):\n    \"\"\"Standardize rows and remove vertical lines\"\"\"\n    res = standardize_rows(arr)\n    res = remove_vertical_lines(res)\n    return res\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.create_binary_mask","title":"create_binary_mask","text":"<pre><code>create_binary_mask(arr, pct_threshold=95)\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def create_binary_mask(arr, pct_threshold = 95):\n    threshold = np.percentile(arr, pct_threshold)\n    return arr &gt; threshold\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.morph_ops","title":"morph_ops","text":"<pre><code>morph_ops(arr, erosion_struct_size=(10, 3), dilation_struct_size=(1, 5))\n</code></pre> <p>Make array binary and perform morphological operations to remove small components.</p> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def morph_ops(arr, erosion_struct_size = (10,3), dilation_struct_size = (1,5)):\n    \"\"\"Make array binary and perform morphological operations to remove small components.\"\"\"\n    arr = binary_dilation(arr, structure=np.ones((3,20)))\n\n    eroded_mask = binary_erosion(arr, structure=np.ones(erosion_struct_size))\n    dilation_mask = binary_dilation(eroded_mask, structure=np.ones(dilation_struct_size))\n    return dilation_mask\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.filtered_components","title":"filtered_components","text":"<pre><code>filtered_components(mask, min_hw_ratio=0.2, min_area=600, min_h_wide_tall=30, min_area_wide_tall=1000)\n</code></pre> <p>Only keep connected components (regions) in binary mask that meet criteria.</p> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def filtered_components(mask, \n                        min_hw_ratio = 0.2, \n                        min_area = 600, \n                        min_h_wide_tall = 30, \n                        min_area_wide_tall = 1000):\n    \"\"\"Only keep connected components (regions) in binary mask that meet criteria.\n    \"\"\"\n\n    filtered_mask = np.zeros_like(mask)\n    region_manager = RegionManager()\n\n    labeled_mask, _ = label(mask)\n    properties = regionprops(labeled_mask)\n\n    for prop in properties:\n        reg = BinaryMaskRegion(bbox=prop.bbox)\n\n        # Two criteria for keeping regions \n            # main criteria for minimum height/width ratio and minimum area\n            # second criteria for bursts that don't pass main ratio but might be type 2 or 5\n        main_criteria = reg.hw_ratio &gt;= min_hw_ratio and reg.area &gt; min_area\n        keep_wide_tall_bursts_criteria = reg.height &gt; min_h_wide_tall and reg.area &gt; min_area_wide_tall\n\n        # If the region meets criteria insert into manager\n        if main_criteria or keep_wide_tall_bursts_criteria:\n            filtered_mask[labeled_mask == prop.label] = 1\n            region_manager.add_region(region=reg)\n\n    # out of all regions added to manager (that passed two criteria in loop above)\n    # we will take the largest 2 regions (if there are &gt;=2) and check two additional criteria\n    # the additional criteria are size_ratio and max_row_diff, more info in RegionManager class\n    filtered_largest_2_regions = region_manager.filter_largest_2_regions()\n\n    return filtered_largest_2_regions, filtered_mask\n</code></pre>"},{"location":"code_reference/utils/preprocessing/#radburst.utils.preprocessing.blur","title":"blur","text":"<pre><code>blur(arr, blur_filter_shape=(51, 11))\n</code></pre> Source code in <code>radburst/utils/preprocessing.py</code> <pre><code>def blur(arr, blur_filter_shape = (51,11)):\n    return cv2.GaussianBlur(arr,blur_filter_shape,0)  \n</code></pre>"},{"location":"code_reference/utils/utils/","title":"Utility Functions","text":"<p>Import utility functions from the <code>utils</code> module:</p> <pre><code>from radburst.utils.utils import load_fits_file\n</code></pre>"},{"location":"code_reference/utils/utils/#radburst.utils.utils","title":"radburst.utils.utils","text":""},{"location":"code_reference/utils/utils/#radburst.utils.utils.load_fits_file","title":"load_fits_file","text":"<pre><code>load_fits_file(fits_file_path, num_freq_chans_to_remove=10)\n</code></pre> <p>Load spectrogram from a FITS into a numpy array.</p> PARAMETER DESCRIPTION <code>fits_file_path</code> <p>Path to .fits file containing the spectrogram data.</p> <p> TYPE: <code>str</code> </p> <code>num_freq_chans_to_remove</code> <p>Optional parameter to remove low frequency channels with bad signal.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> RETURNS DESCRIPTION <p>np.ndarray: Array</p> Source code in <code>radburst/utils/utils.py</code> <pre><code>def load_fits_file(fits_file_path, num_freq_chans_to_remove=10):\n    \"\"\"Load spectrogram from a FITS into a numpy array.\n\n    Args:\n        fits_file_path (str): Path to .fits file containing the spectrogram data.\n        num_freq_chans_to_remove (int): Optional parameter to remove low frequency channels with bad signal.\n\n    Returns:\n        np.ndarray: Array \n    \"\"\"\n    fits_full_data = fits.open(fits_file_path)\n    fits_array = fits_full_data[0].data[:-num_freq_chans_to_remove,:]\n    return fits_array\n</code></pre>"},{"location":"code_reference/utils/utils/#radburst.utils.utils.plot_spectrogram","title":"plot_spectrogram","text":"<pre><code>plot_spectrogram(spect)\n</code></pre> <p>Plot a spectrogram array.</p> PARAMETER DESCRIPTION <code>spect</code> <p>Array of spectrogram data.</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <p>None</p> Source code in <code>radburst/utils/utils.py</code> <pre><code>def plot_spectrogram(spect):\n    \"\"\"Plot a spectrogram array.\n\n    Args:\n        spect (np.ndarray): Array of spectrogram data.\n\n    Returns:\n        None\n    \"\"\"\n    plt.imshow(spect, aspect='auto')    \n</code></pre>"},{"location":"examples/examples/","title":"RadBurst Usage Examples","text":"<p>This section provides practical examples of how to use the RadBurst package for solar radio burst detection and classification.</p>"},{"location":"examples/examples/#1-loading-and-preprocessing-data","title":"1. Loading and Preprocessing Data","text":"<p>Note: This is a placeholder example of the actual implementation of detection and classification.</p> <pre><code>from radburst.utils.utils import load_fits_file\nfrom radburst.utils.preprocessing import standardize_rows\n\n# Load the FITS file\nspectrogram = load_fits_file('path/to/your/fits_file.fits')\n\n# Preprocess the data\npreprocessed_spectrogram = standardize_rows(spectrogram)\n</code></pre>"},{"location":"examples/examples/#2-visualizing-a-spectrogram","title":"2. Visualizing a Spectrogram","text":"<p>Note: This is a placeholder example of the actual implementation of detection and classification.</p> <pre><code>from radburst.utils.utils import plot_spectrogram\nimport matplotlib.pyplot as plt\n\n# Plot the spectrogram\nplot_spectrogram(preprocessed_spectrogram)\nplt.title('Preprocessed Spectrogram')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar(label='Intensity')\nplt.show()\n</code></pre>"},{"location":"examples/examples/#3-detecting-and-classifying-bursts","title":"3. Detecting and Classifying Bursts","text":"<p>Note: This is a placeholder example of the actual implementation of detection and classification.</p> <pre><code>from radburst.detection import detect_bursts\nfrom radburst.classification import classify_bursts\n\ndetected_bursts = detect_bursts(preprocessed_spectrogram)\n\nclassified_bursts = classify_bursts(detected_bursts)\n\nprint(f\"Number of detected bursts: {len(detected_bursts)}\")\nprint(\"Classification results:\")\nfor burst, classification in classified_bursts:\n    print(f\"Burst at {burst['time']} classified as {classification}\")\n</code></pre>"},{"location":"guides/dev_workflow/","title":"Development Workflow","text":"<p>This guide explains the steps to be taken when making changes or updates to this repository.</p>"},{"location":"guides/dev_workflow/#1-create-branch-for-featurefix","title":"1. Create branch for feature/fix","text":"<ul> <li>Allows the user to test changes without affecting the main branch.</li> </ul>"},{"location":"guides/dev_workflow/#2-pull-latest-updates-from-main-branch-to-avoid-conflicts","title":"2. Pull latest updates from main branch to avoid conflicts","text":"<ul> <li>Useful to ensure the user does not overwrite recent changes or do what someone else has already done.</li> <li>Also ensures that any code the user adds will be compatible with existing code.</li> </ul>"},{"location":"guides/dev_workflow/#3-make-changes-update-docs-as-needed","title":"3. Make changes (update docs as needed)","text":"<ul> <li>Change files to achieve the desired results.</li> <li>Will not affect main branch, so minimal risk.</li> </ul>"},{"location":"guides/dev_workflow/#4-commit","title":"4. Commit","text":"<ul> <li>These act as save points. If later code causes issues, a previous commit can be reverted to.</li> </ul>"},{"location":"guides/dev_workflow/#5-push","title":"5. Push","text":"<ul> <li>This allows others to see the branch the user has created and edit it.</li> <li>The branch stays seperate from the main branch.</li> </ul>"},{"location":"guides/dev_workflow/#6-pull-request","title":"6. Pull request","text":"<ul> <li>Proposes merging the new branch with the main branch.</li> <li>Allows for changes to be considered by others; they may notice things the user who created the branch did not.</li> </ul>"},{"location":"guides/dev_workflow/#7-some-team-member-reviews-pull-request-and-gives-feedback-if-they-have-any","title":"7. Some team member reviews pull request and gives feedback if they have any","text":"<ul> <li>example feedback: add comments for clarity, include corresponding documentation, improve variable naming, this part could be simplified.</li> <li>this process can keep team members informed,  encourage better code quality and help us learn from each other's work.</li> </ul>"},{"location":"guides/dev_workflow/#8-merge-branch-into-main","title":"8. Merge branch into main","text":"<ul> <li>Moves the changes made in the branch into the main branch.</li> <li>Ensures that other users will have the updated code when they make branches</li> </ul>"},{"location":"guides/dev_workflow/#9-delete-branch","title":"9. Delete branch","text":"<ul> <li>The commits made are not deleted, only the branch itself</li> </ul>"},{"location":"guides/installation/","title":"Installation","text":"<ol> <li>Clone the GitHub repository: <pre><code>git clone https://github.com/Kasper-Heliophysics-MDP/radburst.git\n</code></pre></li> <li>Move into the project directory: <pre><code>cd draft\n</code></pre></li> <li>Set up a virtual enviroment (to isolate dependencies): <pre><code>python3 -m venv .venv .\n</code></pre></li> <li>Activate the virtual enviroment: <pre><code>. .venv/bin/activate\n</code></pre></li> <li>Install the project and dependencies: <pre><code>pip install -e . \n</code></pre> This installs the project as a package (in \"editable\" mode), enabling you to import it throughout the codebase while reflecting changes made without needing to reinstall.</li> </ol>"},{"location":"guides/update_docs/","title":"Updating Documentation","text":"<p>This guide provides instructions for how to update and maintain project documentation. These steps explain how to make changes, preview them and deploy updates to the documentation site.</p> <p>The documentation site is built using MkDocs. MkDocs reads the Markdown (.md) files from the <code>docs/</code> folder and configures the site according to the settings defined in <code>mkdocs.yml</code>.</p>"},{"location":"guides/update_docs/#1-edit-documentation-files","title":"1. Edit Documentation Files","text":"<ul> <li>Modify <code>.md</code> files in the <code>docs/</code> directory.</li> <li>For Markdown (<code>.md</code>) syntax, refer to the Markdown Guide</li> </ul>"},{"location":"guides/update_docs/#2-code-reference","title":"2. Code Reference","text":"<ul> <li>To automatically generate documentation from your code's doctrings (in modules, functions or classes), use the following syntax in your Markdown files:</li> </ul> <pre><code>::: radburst.utils.preprocessing\n</code></pre> <ul> <li>The line above will read the docstrings in <code>preprocessing.py</code> and create structured documentation that explains the functions, their parameters, and return values.</li> <li> <p>The current <code>mkdocs.yml</code> is configured to use Google-style dosctrings. Here's an example of a Google-style docstring for a function:</p> <pre><code>def example_function(param1, param2):\n    \"\"\"Short description of the function.\n\n    Longer description that provides more detail about what the function does,\n    how it operates, and any important considerations. This can include\n    information about the parameters, return values, and any exceptions that\n    might be raised.\n\n    Args:\n        param1 (int): The first parameter to be processed.\n        param2 (float): The second parameter to be processed.\n\n    Returns:\n        bool: True if the operation is successful, False otherwise.\n    \"\"\"\n    return True\n</code></pre> </li> </ul>"},{"location":"guides/update_docs/#3-updating-mkdocsyml","title":"3. Updating <code>mkdocs.yml</code>","text":"<ul> <li>The <code>mkdocs.yml</code> file in the root directory configures the documentation site. Changes to documentation files/structure will need to be reflected here to make sure the site is rendered correctly.</li> <li> <p>Here is a preview of what it looks like:</p> <pre><code>site_name: RadBurst Documentation\nsite_url: https://Kasper-Heliophysics-MDP.github.io/radburst\n\nrepo_name: Kasper-Heliophysics-MDP/radburst\nrepo_url: https://github.com/Kasper-Heliophysics-MDP/radburst\n\nnav:\n- Home: index.md\n- Developer Guide:\n    - Installation: guides/installation.md\n    - Development Workflow: guides/dev_workflow.md\n    - Updating Documentation: guides/update_docs.md\n- Code Reference:\n    - code_reference/index.md\n</code></pre> </li> </ul>"},{"location":"guides/update_docs/#4-preview-changes-locally","title":"4. Preview Changes Locally","text":"<ul> <li>To preview your changes, run the following command from the project directory:</li> </ul> <p><pre><code>mkdocs serve\n</code></pre> - This will provide a link to view the current documentation in your web browser.</p>"},{"location":"guides/update_docs/#5-build-the-documentation-site-optional","title":"5. Build the Documentation Site (Optional)","text":"<ul> <li>To generate the static site files without deploying, run:</li> </ul> <p><pre><code>mkdocs build\n</code></pre> - This will create site files in <code>site/</code>. Note <code>site/</code> is in <code>.gitignore</code> and this build command is automatically run in the following deployment step. Therefore, if changes look good after previewing with <code>mkdocs serve</code>, building is not required.</p>"},{"location":"guides/update_docs/#6-deploy-the-changes","title":"6. Deploy the Changes","text":"<ul> <li>Once you're satisfied with your changes, they can be deployed:</li> </ul> <p><pre><code>mkdocs gh-deploy\n</code></pre> - This will build the documentation (if not already built), commit changes to the <code>gh-pages</code> branch and push the <code>gh-pages</code> branch to GitHub. The GitHub repo will host the documentation using <code>gh-pages</code>.</p>"}]}